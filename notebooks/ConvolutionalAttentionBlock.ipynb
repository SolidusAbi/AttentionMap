{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Attention Block\n",
    "\n",
    "Propuesta alternativa al CoordinateAttention.\n",
    "\n",
    "Se utiliza kernels de distintos tamaños para obtener descriptores horizontales y verticales, el propósito es obtener descriptores que definan la información espacial de forma complementaria para luego unificar dicha información mediante la adición (o concatenación) de ambos descriptores.\n",
    "\n",
    "De todas formas, no se puede ignorar la información de los canales de cada input. Estos podrían afectar drásticamente a la los descriptores espaciales. Por este motivo, se han aplicado DepthWise Separable convolutions para que cada descriptor no se base toda su información teniendo en cuenta todos los canales, sino un subconjunto de ellos. (Es necesario desarrollar esto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAttentionBlock(nn.Module):\n",
    "    def __init__(self, img_size: tuple, in_channels: int, reduction_rate: int, groups=True, bias=True) -> None:\n",
    "        super(ConvolutionalAttentionBlock, self).__init__()\n",
    "        out_channels = max(8, in_channels // reduction_rate)\n",
    "        H, W = img_size\n",
    "\n",
    "        self.conv_h = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (1, W), bias=bias, groups=out_channels if groups else 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "\n",
    "        self.conv_w = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, (H, 1), bias=bias, groups=out_channels if groups else 1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.SiLU()\n",
    "        )\n",
    "        \n",
    "        self.att = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, in_channels, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x_h = self.conv_h(x) # Height descriptor\n",
    "        x_w = self.conv_w(x) # Width descriptor\n",
    "\n",
    "        # Coordinate attention\n",
    "        coordAtt = self.att(x_h+x_w)\n",
    "        # TODO: Concatenate x_h and x_w\n",
    "        \n",
    "        return coordAtt  \n",
    "\n",
    "class CoordAttConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int, stride: int, padding: int, groups: int, bias: bool) -> None:\n",
    "        super(CoordAttConv, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "        \n",
    "        # self.att_block = CoordinateAttentionBlock(out_channels, out_channels, att_reduction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNet-18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import conv3x3, conv1x1, Bottleneck\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None, input_size=None, **kargs):\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], **kargs)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0], **kargs)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1], **kargs)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2], **kargs)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False, **kargs):\n",
    "        print(kargs)\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer, **kargs))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None, **kargs):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        print(kargs)\n",
    "        print(inplanes)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import BasicBlock\n",
    "\n",
    "class ResAttentionBlock(BasicBlock):\n",
    "    def __init__(self, img_size: tuple, inplanes:int, planes:int, stride=1, downsample=None, \n",
    "                att_reduction=8, att_groups=True, att_bias=True, **kargs):\n",
    "                 \n",
    "        super(ResAttentionBlock, self).__init__(inplanes, planes, stride, downsample)\n",
    "\n",
    "        self.attention = ConvolutionalAttentionBlock(img_size, planes, att_reduction, \n",
    "                    groups=att_groups, bias=att_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        att = self.attention(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        res = self.relu((att*out) + identity)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1452, 0.0000, 0.0000,  ..., 0.0000, 0.1423, 1.1244],\n",
       "          [0.3389, 0.0000, 1.6299,  ..., 0.0966, 1.2071, 0.7163],\n",
       "          [0.0000, 0.0000, 0.6837,  ..., 1.6847, 0.0000, 0.0856],\n",
       "          ...,\n",
       "          [0.3527, 1.2866, 0.0000,  ..., 0.3138, 0.0000, 0.4681],\n",
       "          [0.1139, 0.0000, 0.0000,  ..., 0.9910, 0.4116, 1.4662],\n",
       "          [1.3024, 1.5806, 1.0227,  ..., 1.6218, 2.4134, 1.0917]],\n",
       "\n",
       "         [[0.0000, 0.0921, 0.2776,  ..., 0.6466, 1.1902, 0.3347],\n",
       "          [0.9279, 0.0774, 0.1865,  ..., 0.0000, 0.7676, 0.0430],\n",
       "          [0.0739, 0.0591, 0.6241,  ..., 1.4331, 0.9105, 0.5466],\n",
       "          ...,\n",
       "          [1.1355, 0.0000, 1.4560,  ..., 0.2645, 1.4166, 1.0860],\n",
       "          [0.3188, 0.8262, 1.9807,  ..., 0.4303, 1.6467, 0.0555],\n",
       "          [0.0929, 0.1579, 0.5086,  ..., 0.4295, 0.1069, 0.3421]],\n",
       "\n",
       "         [[0.5223, 0.0000, 0.9467,  ..., 0.3550, 0.7645, 0.6179],\n",
       "          [1.0765, 0.7996, 1.9936,  ..., 0.8632, 1.2247, 0.9293],\n",
       "          [0.0000, 1.4586, 0.4162,  ..., 0.8765, 0.7404, 1.6328],\n",
       "          ...,\n",
       "          [0.4170, 0.0000, 0.8986,  ..., 0.4253, 0.0000, 0.2290],\n",
       "          [0.6227, 0.0348, 0.0681,  ..., 1.1961, 1.3912, 1.3506],\n",
       "          [0.7325, 1.7061, 0.0899,  ..., 1.3775, 1.0533, 0.3653]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.2162, 0.0622, 0.0000,  ..., 0.0000, 0.4959, 0.0000],\n",
       "          [0.2379, 0.1350, 0.2331,  ..., 0.2744, 1.4436, 1.1646],\n",
       "          [0.3200, 1.0115, 0.0000,  ..., 1.2200, 1.6693, 0.8975],\n",
       "          ...,\n",
       "          [0.4312, 0.0000, 0.3699,  ..., 0.9734, 1.3556, 1.1582],\n",
       "          [0.0603, 0.0244, 0.6864,  ..., 0.2859, 0.9443, 0.2468],\n",
       "          [0.1330, 0.4108, 0.5181,  ..., 0.1527, 0.4738, 0.7798]],\n",
       "\n",
       "         [[0.0804, 0.5837, 0.9839,  ..., 0.3501, 0.4404, 0.2929],\n",
       "          [0.7824, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6042, 0.8621, 0.6340,  ..., 0.5962, 0.1790, 0.0000],\n",
       "          ...,\n",
       "          [0.5657, 0.7382, 0.7737,  ..., 0.7978, 1.0634, 0.8965],\n",
       "          [0.1437, 1.2200, 0.4522,  ..., 0.0000, 0.1977, 1.0641],\n",
       "          [0.0000, 0.5373, 1.5917,  ..., 0.5539, 0.4481, 0.7308]],\n",
       "\n",
       "         [[1.2007, 0.9670, 0.6580,  ..., 0.4990, 0.7797, 0.0000],\n",
       "          [0.6173, 0.0000, 0.8290,  ..., 0.0000, 0.4310, 0.1016],\n",
       "          [0.6973, 0.6924, 0.8492,  ..., 0.6651, 0.5983, 0.7020],\n",
       "          ...,\n",
       "          [1.4036, 1.2950, 0.9654,  ..., 1.0478, 0.2161, 0.0000],\n",
       "          [1.1982, 0.8717, 1.1732,  ..., 1.3313, 0.3317, 1.2078],\n",
       "          [0.9257, 0.9710, 1.2610,  ..., 0.9878, 0.7066, 0.1706]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# att_block = ResAttentionBlock((128,128), 64, 64)\n",
    "# # att_block(torch.rand(1,64,128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block = BasicBlock(64, 64)\n",
    "block(torch.rand(1,64,128,128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet\n",
    "import numpy as np\n",
    "\n",
    "class ResNet_Attention(ResNet):\n",
    "    def __init__(self, img_size:tuple, block:nn.Module, layers:list, num_classes=1000, **kargs):\n",
    "        super(ResNet_Attention, self).__init__(BasicBlock, layers, num_classes, kargs)\n",
    "\n",
    "        if not isinstance(img_size, np.ndarray):\n",
    "            img_size = np.array(img_size)\n",
    "\n",
    "        self.inplanes = 64 # Because in super init it has been set to 512\n",
    "        self.layer1 = self._make_attention_layer(tuple(img_size // (2**2)), block, 64, layers[0], **kargs)\n",
    "        self.layer2 = self._make_attention_layer(tuple(img_size // (2**3)), block, 128, layers[1], stride=2,\n",
    "                                       dilate=False, **kargs)\n",
    "        self.layer3 = self._make_attention_layer(tuple(img_size // (2**4)), block, 256, layers[2], stride=2,\n",
    "                                       dilate=False, **kargs)\n",
    "        self.layer4 = self._make_attention_layer(tuple(img_size // (2**5)), block, 512, layers[3], stride=2,\n",
    "                                       dilate=False, **kargs)\n",
    "        \n",
    "    def _make_attention_layer(self, input_size, block, planes, blocks, stride=1, dilate=False, **kargs):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(input_size, self.inplanes, planes, stride, downsample, \n",
    "                    groups=self.groups, base_width=self.base_width, dilation=previous_dilation,\n",
    "                    norm_layer=norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(input_size, self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n",
      "128\n",
      "256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models.resnet import BasicBlock\n",
    "test = ResNet_Attention((128,128), ResAttentionBlock, [1,2,2,2], num_classes=1000)\n",
    "\n",
    "result = test(torch.rand(1,3,128,128))\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet_Attention(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): ResAttentionBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(64, 8, kernel_size=(1, 32), stride=(1, 1), groups=8)\n",
       "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(64, 8, kernel_size=(32, 1), stride=(1, 1), groups=8)\n",
       "          (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(8, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): ResAttentionBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(128, 16, kernel_size=(1, 16), stride=(1, 1), groups=16)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(128, 16, kernel_size=(16, 1), stride=(1, 1), groups=16)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResAttentionBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(128, 16, kernel_size=(1, 16), stride=(1, 1), groups=16)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(128, 16, kernel_size=(16, 1), stride=(1, 1), groups=16)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): ResAttentionBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(256, 32, kernel_size=(1, 8), stride=(1, 1), groups=32)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(256, 32, kernel_size=(8, 1), stride=(1, 1), groups=32)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResAttentionBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(256, 32, kernel_size=(1, 8), stride=(1, 1), groups=32)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(256, 32, kernel_size=(8, 1), stride=(1, 1), groups=32)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): ResAttentionBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(512, 64, kernel_size=(1, 4), stride=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(512, 64, kernel_size=(4, 1), stride=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResAttentionBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (attention): ConvolutionalAttentionBlock(\n",
       "        (conv_h): Sequential(\n",
       "          (0): Conv2d(512, 64, kernel_size=(1, 4), stride=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (conv_w): Sequential(\n",
       "          (0): Conv2d(512, 64, kernel_size=(4, 1), stride=(1, 1), groups=64)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): SiLU()\n",
       "        )\n",
       "        (att): Sequential(\n",
       "          (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_size = np.array((128, 128))\n",
    "input_size\n",
    "\n",
    "input_size // 2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18 = ResNet(BasicBlock, [2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64, 64])\n",
      "torch.Size([1, 64, 32, 32])\n",
      "1 torch.Size([1, 64, 32, 32])\n",
      "torch.Size([1, 128, 16, 16])\n",
      "torch.Size([1, 256, 8, 8])\n",
      "torch.Size([1, 512, 4, 4])\n",
      "torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a = torch.rand((1,3,128,128))\n",
    "a = resnet_18.conv1(a)\n",
    "a = resnet_18.bn1(a)\n",
    "print(a.shape)\n",
    "a = resnet_18.maxpool(a)\n",
    "print(a.shape)\n",
    "a = resnet_18.layer1(a)\n",
    "print(\"1\", a.shape)\n",
    "a = resnet_18.layer2(a)\n",
    "print(a.shape)\n",
    "a = resnet_18.layer3(a)\n",
    "print(a.shape)\n",
    "a = resnet_18.layer4(a)\n",
    "print(a.shape)\n",
    "a = resnet_18.avgpool(a)\n",
    "print(a.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 // (2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "128 // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tuple(np.array((128,128)) // 2**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('DeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d9b8aa8d774518be7ebcfd06a2463a8035a66798fac49b1a363f570d2d8622e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
